<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>99 实践 on</title><link>https://guowei1651.github.io/devops/99.practice/</link><description>Recent content in 99 实践 on</description><generator>Hugo -- gohugo.io</generator><lastBuildDate>Sat, 22 Apr 2023 12:52:56 +0800</lastBuildDate><atom:link href="https://guowei1651.github.io/devops/99.practice/index.xml" rel="self" type="application/rss+xml"/><item><title>0-理论--SCM代码仓库管理--Git的实际使用</title><link>https://guowei1651.github.io/devops/99.practice/0-%E7%90%86%E8%AE%BA--scm%E4%BB%A3%E7%A0%81%E4%BB%93%E5%BA%93%E7%AE%A1%E7%90%86--git%E7%9A%84%E5%AE%9E%E9%99%85%E4%BD%BF%E7%94%A8/</link><pubDate>Sat, 22 Apr 2023 12:52:56 +0800</pubDate><guid>https://guowei1651.github.io/devops/99.practice/0-%E7%90%86%E8%AE%BA--scm%E4%BB%A3%E7%A0%81%E4%BB%93%E5%BA%93%E7%AE%A1%E7%90%86--git%E7%9A%84%E5%AE%9E%E9%99%85%E4%BD%BF%E7%94%A8/</guid><description>背景 # 在软件过程中
问题 # 为什么git的三大流程（git flow,github flow,gitlab flow）都没有测试分支，没有验证分支？只有开发，预生产，生产？而且顺序都是还是主分支推到预生产、生产？
问题原因 # 这只能说工程水平不在同一个等级，等工程水平到达一定等级之后才会真正的感觉到这几个flow的好处。
实际使用Git # 总结 # 一个成功的Git分支模型 别再推荐Git Flow了</description></item><item><title>Gradle使用小结</title><link>https://guowei1651.github.io/devops/99.practice/gradle%E4%BD%BF%E7%94%A8%E5%B0%8F%E7%BB%93/</link><pubDate>Sat, 22 Apr 2023 12:52:56 +0800</pubDate><guid>https://guowei1651.github.io/devops/99.practice/gradle%E4%BD%BF%E7%94%A8%E5%B0%8F%E7%BB%93/</guid><description>概述 # Gradle是CI过程工具，而不是系统。持续集成过程中的构建、自动化测试、打包、发布都可以使用Gradle来完成。而持续进程过程为我们降低各方面成本，提高产品信心，提高产品质量有着非常重要的作用（不要问我为啥）。而我们很多研发人员非常讨厌CI过程，这一点的问题原因是研发人员没有从CI过程中获取任何利益，而且还增加了维护成本。关于这一点等有机会的时候和大家讨论一下《怎么统一研发，质量，测试，管理之间的利益》（统一各方面的利益之后众志成城，万众一心，我们的产品会更上一层楼)。
使用总结： # 在使用Gradle过程中发现在Gradle中的很多特性，很多原理都很特别。这里说明几个使用实践。（这里不与makefile，maven，ant进行对比）
关于Gradle的执行的过程： # 很多介绍Gradle的地方，都说Gradle脚本是一种配置脚本。他们说这句话的原因是因为在Gradle中提供了很多插件，启用插件后直接调用方法闭包进行配置就可以完全完成项目需要的功能。所以，Gradle很多时候都是以配置文件的形式存在的。
但，Gradle的脚本不简单是配置文件。从Gradle执行的三个步骤可以看出： 1&amp;gt; Initialization：Gradle 支持单项目或者多项目构建，在该阶段，Gradle认哪些项目会参与构建，然后为每一个项目创建 Project 对象 2&amp;gt; Configuration：这个阶段就是配置 Initialization 阶段创建的 Project 对象，所有的配置脚本都会被执行 3&amp;gt; Execution：这个阶段 Gradle 会确认哪些在 Configuration 阶段创建和配置的 Task 会被执行，哪些 Task会被执行取决于gradle命令的参数以及当前的目录，确认之后便会执行
大家可以从Gradle执行过程得出，Gradle的使用过程不止配置脚本那么简单。具体可以看： 1&amp;gt; 在初始化阶段，Gradle没有指定默认的初始化脚本，必须使用Gradle的命令行参数进行指定。这个过程可以使用Gradle的Hook来完成相应的回调注册，以控制整个Gradle执行过程。
参见：https://docs.gradle.org/current/userguide/init_scripts.html https://docs.gradle.org/current/dsl/org.gradle.api.invocation.Gradle.html#org.gradle.api.invocation.Gradle:addListener(java.lang.Object)
2&amp;gt; 在配置阶段，执行的是相关的配置。比如说Project中的依赖管理闭包块。属性设置等都会直接执行。但是这个阶段不会执行task内部的action。所以，这个阶段才叫做配置阶段。
3&amp;gt; 在执行阶段，会执行task的相关操作。在相对复杂的项目中很多时候需要在执行阶段对项目构建进行动态配置，在这个阶段可以对项目中各种属性在进行配置。但是，动态配置过程必须在使用这些配置之前完成，要不也没有任何用处。
所以，从上面可以得出，Gradle的执行过程不像我们之前接触过的CI工具那样要不是纯配置，要不是纯动态。这一点是Gradle很大的特点。这种方式为我们很好的融合了配置 与 动态构建过程，平衡了两方的优缺点。
Gradle配置过程 # 在脚本执行的时候，Gradle会配置一些特定类型的对象，这些对象就被称为脚本的 delegate 对象，也是构建领域的领域对象，下文简称 DO。 DO 的意义就在于脚本可以使用被代理的对象的方法——这一点非常重要，是脚本中可调用方法的重要来源。 参见：https://www.muzileecoding.com/gradlestudy/gradle-advaced-do.html
只要是被委托对象有的方法，都是可以直接调用的。而且还有一个比较复杂的方法查找过程，一层层的查找方法。所以，在查找在某一部分可以使用的方法是一个比较麻烦的过程。而在Gradle中的文档又写的很晦涩会导致学习成本提升，效率降低等问题。不过一般情况下直接查找DSL相关描述即可。
Gradle脚本模块化 # 模块化过程分两个大类：配置模块化 和 过程模块化。 配置模块化是将Gradle的脚本分模块的写道不同的脚本下，来提高Gradle脚本的可读性与可维护性。具体方法：
apply from: 'other.gradle' 使用apply来引入其他的脚本，但是，在真正使用过程中发现被引入的脚本的委托对象好像不像一般脚本那样。不能直接使用Project一些特定的属性或者task，只能在主脚本中通过不同的方式进行调用。
过程模块化是在被引入脚本中实现过程，方法，类等等，但是需要在主脚本里进行调用。这种方法可以使用Gradle直接调用groovy脚本中的实现来完成，但是，没有找到方法来使Gradle脚本调用groovy脚本。所以，这里的过程模块化还是使用配置模块化来进行引入。不过使用特殊的方式进行方法，类的导出。具体如下：
// Define methods as usual def commonMethod1(param){ return true } def commonMethod2(param){ return true } // Export methods by turning them into closures ext{ commonMethod1 = this.</description></item><item><title>Jenkins的环境管理讨论</title><link>https://guowei1651.github.io/devops/99.practice/01-jenkins%E7%9A%84%E7%8E%AF%E5%A2%83%E7%AE%A1%E7%90%86%E8%AE%A8%E8%AE%BA/</link><pubDate>Sat, 22 Apr 2023 12:52:56 +0800</pubDate><guid>https://guowei1651.github.io/devops/99.practice/01-jenkins%E7%9A%84%E7%8E%AF%E5%A2%83%E7%AE%A1%E7%90%86%E8%AE%A8%E8%AE%BA/</guid><description>DevOps实践系列文章，请参见连接。
背景 # 在经过公司内部自研持续交付环境，再到使用很长时间的Jenkins之后。对于持续交付工具的一些特点有一定认识。在为软件开发流程设计持续交付过程中需要考虑到很多方面的内容。一般通用的持续集成系统中都会设计到以下几个部分：
环境管理。在持续集成环境中包括很多类型的环境。例如：持续交付运行环境，编译环境，存储环境，发布环境，被测环境，测试环境等等。之前在通信行业进行持续交付环境构建时，考虑到硬件资源以及硬件型号的问题对于不同的硬件型号需要运行不同的构建与测试过程。 Pipeline流程。为持续交付提供流程、步骤的支持，可以使用原子操作、组合操作进行组合形成一套Pipeline流程。最终满足持续交付的过程需要。 原子操作。针对通信行业中的交付过程，可能涉及到不同的网元。对于网元间版本控制与接口对接的以及测试要求需要考虑。所以，原子操作可以拆成对网元的操作。对于互联网应用中的微服务体系的操作，可以定义一套编译，构建，发布是原子操作。每个微服务都是由这些原子操作的过程组成，然后这些微服务的统一管理的pipeline又可以是一个更上层的流程。 结果展示。各项结果都需要有好的展示出来。代码扫描结果，编译结果，流程结果，原子操作结果等等都是需要展示出来的。 综上，要构建一套持续交付环境需要对各个层级有比较清晰的认识之后再做环境构建时是比较好的。本篇文章着重讨论环境管理部分的内容。
环境管理发展 # 环境管理发展描述从比较单一的持续构建环境一路发展为环境即代码环境管理方式。这个过程从某个侧面可以认为是IT业界对环境管理过程的认知升级的过程。一步步的从手动管理环境到自动化调度、控制环境的过程。
1. 直接使用Jenkins服务器做为构建环境 # 在刚开始接触Jenkins时，一般都会使用Jenkins Server作为我们所有动作执行的地方。在Jenkins Server上执行代码Checkout，编译，依赖管理，制品管理。慢慢的随着要处理的微服务个数，要存储的制品、要做的频率不断的提升会逐渐的觉得只使用Jenkins Server完成这些工作比较吃力。想办法逐渐的把各项工作分散到不同的机器上完成。可能通过ssh，ansible，chef等工具完成。
2. 使用Jenkins的Node管理作为构建环境 # 在用ssh一段时间之后，发现ssh的服务器只能通过代码进行管理。在同时执行一个Job的时候回发生环境冲突的问题。ssh不能进行环境调度的工作，只能将Job和主机绑定。从这个时候开始借助Jenkins Agent来进行辅助服务器的管理工作。使用Jenkins Agent可以对服务器进行包活，任务调度的管理。
3. 使用Docker作为Node进行环境管理 # 在经过对Job的调度工作时候，慢慢的发现每个Agent都是一个持续交付的环境。每个Agent上跑着所有的任务，任务都在Agent上存储一部分Job数据。Job间可能会造成排队与存储干扰的问题。在持续交付环境管理中已经投入了机器的情况下，还是会遇到一些环境的一些问题。就需要考虑怎样处理这些问题。正好Docker第一个功能就是做环境隔离的工作。用Docker将不同的环境隔离出来，例如：专门做Node编译的，专门做Java编译的，专门做C#编译的，专门做发布的。都可以独立的隔离出来，这样可以按照持续交付的步骤进行环境的隔离，解决排队和干扰的问题。
4. 使用一次性Docker容器作为Node的环境管理 # 慢慢的固定的Docker容器去做工作，会发现Docker很多时候都是空闲的。所以，就想怎样提高资源的利用率。开始使用一次性Docker解决问题，最终可以做到随建随走，随用随走。
5. 使用环境即代码的方式管理环境 # 在Docker的仓库，Docker与物理机之间的关系等在发展到一定阶段之后也是需要进行大量的管理的。这个时候Docker的调度，Docker的恢复，Docker的监控，Docker的镜像等都需要进行管理。在这个使用控制环境如果还是使用某种二进制包+说明文档的方式进行管理就不能很好的完成工作了。这个时候就明显的需要对环境进行版本化管理，对环境进行版本化管理可以很快的复制一套相同的环境做其他用途。
实现方式 # 从上面的环境管理发展可以总结出环境管理的几个要点任务：
环境包活 任务调度 环境隔离 资源利用率 环境管理版本化 针对每一个发展阶段都有它自己的技术特点。每个阶段的技术主要内容有：
Jenksin、Gitlab、TeamCity、Travis CI Agent Docker Swarm，K8s，ansible 这里给出来一个Jenkins上使用一次性Docker的一个例子：
环境构建 配置Pipeline pipeline { agent { docker { image 'maven:3.3.3' args '-v /tmp:/tmp -v $HOME/.m2:/root/.m2 -v /opt/docker/ci/pmd/p3c:/opt/p3c -v p3c_result:/opt/result' } } options { timeout(time: 1, unit: 'HOURS') } stages { stage(&amp;quot;init workspace&amp;quot;) { steps { cleanWs() } } stage(&amp;quot;checkout code&amp;quot;){ steps { echo &amp;quot;checkout code&amp;quot; checkout([$class: 'GitSCM', branches: [[name: '*/dev']], doGenerateSubmoduleConfigurations: false, extensions: [], submoduleCfg: [], userRemoteConfigs: [[credentialsId: 'wales_kuo', url: git_url]]]) } } stage(&amp;quot;scan code&amp;quot;){ steps { echo &amp;quot;scan code&amp;quot; sh ''' export p3c_jar_path=&amp;quot;/opt/p3c/p3c-pmd-2.</description></item><item><title>SCM代码仓库管理</title><link>https://guowei1651.github.io/devops/99.practice/02-scm%E4%BB%A3%E7%A0%81%E4%BB%93%E5%BA%93%E7%AE%A1%E7%90%86/</link><pubDate>Sat, 22 Apr 2023 12:52:56 +0800</pubDate><guid>https://guowei1651.github.io/devops/99.practice/02-scm%E4%BB%A3%E7%A0%81%E4%BB%93%E5%BA%93%E7%AE%A1%E7%90%86/</guid><description>背景 # 人在不同的阶段对于同一件事会有不同的理解。而且每个人都来说个人方向选择、精力与经历都左右着对同一件事情的理解。所以，
三人行，则必有我师。是故弟子不必不如师，师不必贤于弟子，闻道有先后，术业有专攻，如是而已。 &amp;ndash;《师说》韩愈
抱着开放的心态学习每一个比你优秀的人的优点。就是我们这些软件从业者应该做的。抱着为软件业做一份贡献的执着的心情，持续得在这个行业里钻研和研究。
在软件公司之间最大的差别是什么？最大的差别在于公司的文化。不管是工程师文化、敏捷文化、精益MVP文化、商业目标文化，都是为了公司更好的发展以及在行业内与其他竞品进行竞争。这个文化最大的指导意义是指导软件团队的可靠性与效率。
对于完整的DevOps体系来说普元的王海龙的这张图可以非常完整的说明整个DevOps中所有的方面的内容：
在DevOpsMaster上 还有DevOps工具集的集合： 介绍 # 对于公司内部软件公司内部比较重要的几件事：业务方案，软件过程，技术方案，基础设施。
对于SCM(Source Contronl Management)来说应该在DevOps中的位置可以在上面看到，SCM是用来支撑DevOps的基础设施。它为DevOps流程提供最基础的原材料（代码）的管理工作。所以在SCM之上我们应该追求的更多，最求满足各个层面的要求。要支持业务方案的变化，要支持软件过程，要支持技术方案管理，要支持基础设施的配置管理。并且要支持团队的工作量化，质量量化，效率改进等内容。
技术选型 # 在软件业界有各个方面可以提供代码托管服务，并且很多代码托管系统都可以与云设备进行深度的融合工作。深度融合后的代码托管服务在加上《一切即代码》理念，就可以管理代码、依赖、编译、配置、流程、设备等。下面对代码托管服务进行技术选型评比：
对于可以私有化部署，并且支持更好的公司协作。费用又较低的只有Gitlab可以满足要求。GitHub，BitBucket可以私有化部署，可以支持很多功能，有完善的工具链。但Gitlab的开源协议是MIT License。并且GitLab在企业内部的使用率也很高。
技术实践 # 直接使用Docker镜像进行安装。使用omnibus-gitlab的docker-compose.yml直接启动Docker即可。
Git协议端口修改 # 中间需要注意的是，因为Git使用了SSH的端口，需要将SSH的端口修改为其他端口。将TCP22留给SSH使用。
备份工作 # 配置备份与镜像方式。在每个Git仓库中进行Mirroring的配置即可，但是需要每个项目独立配置。在使用过程中因为使用invalid multibyte char (US-ASCII),在网上搜索后发现是因为中文问题不能处理导致。所以重新进行Docker build：
FROM gitlab/gitlab-ce MAINTAINER GitLab Inc. &amp;lt;support@gitlab.com&amp;gt; SHELL [&amp;quot;/bin/sh&amp;quot;, &amp;quot;-c&amp;quot;], # Install required packages RUN apt-get update -q \ &amp;amp;&amp;amp; DEBIAN_FRONTEND=noninteractive yum groupinstall -y chinese-support &amp;amp;&amp;amp; rm -rf /var/lib/apt/lists/* \ # Default to supporting utf-8 ENV LANG=en_US.UTF-8 配置并设置好语言后发现仍不可用。已经不报错了，但是同步一直没有结束。另外在检查Gitlab API时没有关于调用Mirror同步的API。所以，这里不考虑这种方式进行同步。</description></item><item><title>TCPCopy科普</title><link>https://guowei1651.github.io/devops/99.practice/tcpcopy%E7%A7%91%E6%99%AE/</link><pubDate>Sat, 22 Apr 2023 12:52:56 +0800</pubDate><guid>https://guowei1651.github.io/devops/99.practice/tcpcopy%E7%A7%91%E6%99%AE/</guid><description>元问题 # 问题的根本是什么？
为什么网上所有的TCPCopy介绍文档都这么难以理解？ 为什么需要全链路压测？ 全链路压测应该怎么做？ 解决问题的办法 # TCPCopy介绍 # 总结 #</description></item><item><title>关于logstash-output-mongodb的一点质疑</title><link>https://guowei1651.github.io/devops/99.practice/%E5%85%B3%E4%BA%8Elogstash-output-mongodb%E7%9A%84%E4%B8%80%E7%82%B9%E8%B4%A8%E7%96%91/</link><pubDate>Sat, 22 Apr 2023 12:52:56 +0800</pubDate><guid>https://guowei1651.github.io/devops/99.practice/%E5%85%B3%E4%BA%8Elogstash-output-mongodb%E7%9A%84%E4%B8%80%E7%82%B9%E8%B4%A8%E7%96%91/</guid><description>背景 # 使用的Logstash版本是7.4.2，使用的logstash-output-mongodb版本是3.1.6。基本配置如下：
input { beats { port =&amp;gt; 5044 } } filter { mutate { remove_field =&amp;gt; [&amp;quot;log_type&amp;quot;] remove_field =&amp;gt; [&amp;quot;offset&amp;quot;] remove_field =&amp;gt; [&amp;quot;input&amp;quot;] remove_field =&amp;gt; [&amp;quot;log&amp;quot;] remove_field =&amp;gt; [&amp;quot;input&amp;quot;] remove_field =&amp;gt; [&amp;quot;log&amp;quot;] remove_field =&amp;gt; [&amp;quot;ecs&amp;quot;] remove_field =&amp;gt; [&amp;quot;@version&amp;quot;] remove_field =&amp;gt; [&amp;quot;@timestamp&amp;quot;] remove_field =&amp;gt; [&amp;quot;host&amp;quot;] remove_field =&amp;gt; [&amp;quot;agent&amp;quot;] remove_field =&amp;gt; [&amp;quot;tags&amp;quot;] } json { source =&amp;gt; &amp;quot;message&amp;quot; remove_field =&amp;gt; [&amp;quot;message&amp;quot;] } geoip { source =&amp;gt; &amp;quot;remote_addr&amp;quot; target =&amp;gt; &amp;quot;addr_info&amp;quot; } mutate { remove_field =&amp;gt; [&amp;quot;tags&amp;quot;] } } output { stdout {} mongodb { collection =&amp;gt; &amp;quot;XXXX&amp;quot; database =&amp;gt; &amp;quot;XXXX&amp;quot; uri =&amp;gt; &amp;quot;mongodb://XXX:XXX@XXX:27017&amp;quot; } } 问题 # logstash的问题 # 时间戳logstash自动改，而且还不带时区。 最主要的问题是大家的处理方法都是给时间加上8个小时来处理时间。查找Logstash的时区设置很难找到相关资料，并且所有的参数设置后都无法生效。</description></item><item><title>解决Linux系统buff/cache过大的问题</title><link>https://guowei1651.github.io/devops/99.practice/%E8%A7%A3%E5%86%B3linux%E7%B3%BB%E7%BB%9Fbuff-cache%E8%BF%87%E5%A4%A7%E7%9A%84%E9%97%AE%E9%A2%98/</link><pubDate>Sat, 22 Apr 2023 12:52:56 +0800</pubDate><guid>https://guowei1651.github.io/devops/99.practice/%E8%A7%A3%E5%86%B3linux%E7%B3%BB%E7%BB%9Fbuff-cache%E8%BF%87%E5%A4%A7%E7%9A%84%E9%97%AE%E9%A2%98/</guid><description>解决Linux系统buff/cache过大的问题</description></item></channel></rss>