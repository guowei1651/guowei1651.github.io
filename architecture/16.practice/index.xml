<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>16.实践 on</title><link>https://guowei1651.github.io/architecture/16.practice/</link><description>Recent content in 16.实践 on</description><generator>Hugo -- gohugo.io</generator><lastBuildDate>Sat, 22 Apr 2023 12:52:56 +0800</lastBuildDate><atom:link href="https://guowei1651.github.io/architecture/16.practice/index.xml" rel="self" type="application/rss+xml"/><item><title>01 叫你怎样搭建一个类似的SpringBoot的框架？</title><link>https://guowei1651.github.io/architecture/16.practice/01-%E6%95%99%E4%BD%A0%E6%80%8E%E6%A0%B7%E6%90%AD%E5%BB%BA%E4%B8%80%E4%B8%AA%E7%B1%BB%E4%BC%BCspringboot%E7%9A%84%E6%A1%86%E6%9E%B6/</link><pubDate>Sat, 22 Apr 2023 12:52:56 +0800</pubDate><guid>https://guowei1651.github.io/architecture/16.practice/01-%E6%95%99%E4%BD%A0%E6%80%8E%E6%A0%B7%E6%90%AD%E5%BB%BA%E4%B8%80%E4%B8%AA%E7%B1%BB%E4%BC%BCspringboot%E7%9A%84%E6%A1%86%E6%9E%B6/</guid><description>SpringBoot实战(第4版) &amp;ndash;第四章：测试
有人说，如果你不知道要去哪，走就是了。但在软件开发领域，如果你没有目标，那结果往往是开发出一个满是bug的应用程序，没人用得了。
Hypermedia REST：https://jozdoo.github.io/rest/2016/09/22/REST-HATEOAS.html 使用 Spring HATEOAS 开发 REST 服务：https://www.ibm.com/developerworks/cn/java/j-lo-SpringHATEOAS/index.html 终于找到了一个靠谱的REST介绍：http://blog.51cto.com/hcc0926/1679791 好RESTful API的设计原则：https://www.cnblogs.com/moonz-wu/p/4211626.html</description></item><item><title>02 搭建大数据框架（十分钟学会）</title><link>https://guowei1651.github.io/architecture/16.practice/02-%E6%90%AD%E5%BB%BA%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%A1%86%E6%9E%B6%E5%8D%81%E5%88%86%E9%92%9F%E5%AD%A6%E4%BC%9A/</link><pubDate>Sat, 22 Apr 2023 12:52:56 +0800</pubDate><guid>https://guowei1651.github.io/architecture/16.practice/02-%E6%90%AD%E5%BB%BA%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%A1%86%E6%9E%B6%E5%8D%81%E5%88%86%E9%92%9F%E5%AD%A6%E4%BC%9A/</guid><description>十分钟让你透彻理解大数据的工作方式。大数据并不是深不可测、高不可攀的技术，这里用18页ppt为你深入的理解大数据，学习大数据做好充分的准备。
结合大数据实际使用与开发流程讲述大数据中方方面面的内容。可以一次完整的了解大数据落地过程中需要考虑的问题，需要解决的问题呈现出一个可以真实，完整，落地的大数据服务平台。
概述 # 说明大数据分析的意义，并抽象大数据处理过程。以更通用的理解方式说明大数据的特点。
大数据过程 # 用通俗的语言介绍大数据分析、挖掘过程。
原始的数据是十分杂乱的，在数据经过梳理和清洗，才能够称为信息。信息会包含很多规律，我们需要从信息中将规律总结出来，称为知识（Knowledge），而知识改变命运。有了知识，然后利用这些知识去应用于实战，有的人会做得非常好，这个东西叫做智慧（Intelligence）。
用一种简单的方式说明就是收集来的数据有很多噪音，异常不能直接成为有效信息，进过梳理，过滤，清洗之后形成有用信息。然后在有用的信息中找到某种规律就变成了可以提高认知的知识。然后知识运用到之后的工作中就变成了智慧。
最终的阶段是很多企业都想要的。你看我收集了这么多的数据，能不能基于这些数据来帮我做下一步的决策，改善我的产品。
大数据分析也不是绝对的，有漏洞也有失误，我们不能迷信。虽然大数据分析通常是会凌驾于专家直觉经验之上的，但直觉在选择数据分析之初起着关键性作用。所以，未来我们需要同过直觉、经验、统计数字来做好很多决策。而学好大数据分析，除了那些大的政府决策或者行业、机构决策（医疗改革、影视发行、图书名称等），我们的日常生活也是可以通过这种思维受益的。 统计中所谓的“因果”是“某种”意义的“因果”，即统计学只讨论“原因的结果”，而不讨论“结果的原因”。前者是可以用数据证明或者证伪的；后者是属于科学研究所探索的。用科学哲学家卡尔·波普的话来说，科学知识的积累是“猜想与反驳”的过程：“猜想”结果的原因，再“证伪”原因的结果；如此循环即科学。
大数据分析过程 # 介绍大数据分析实施过程
大数据分析过程是从数据建模开始，然后是将模型加入的系统中，然后等待真实数据的反馈再进行。再进入对数据模型的持续优化过程中。 整体规划：整体规划是规划系统中数据的建模规范，分析维度，分析过程，技术体系，实践规范等等内容。用以管理整个DMP体系中所有的内容。 数据建模：根据业务对业务关心的指标、维度进行定义。并针对这些指标维度进行相关的数据算法的统计。 分析实践：根据建模结果，通过技术的支持形成真正能够在实践环境中使用的代码或者展示。 效果反馈：数据分析结果是有度量的。怎样定义一个数据模型在真实数据环境中的效果是一门独立的学问。 技术支持：以最高效、最低正本支持数据分析的各种工具。包括数据建模，数据可视化，数据挖掘，数据分析等等工具的技术支持。 总结：很多地方不说明大数据的整体过程，只说明其中的很小一部分。导致技术落地困难。 数据建模 # 数据建模是大数据分析的核心。它决定了大数据分析的最终效果。
适合分析的业务 # 大数据能够解决的问题。说明大数据处理问题的特点。 在对复杂问题进行分析与解决时总会使用的解决步骤： 发生了什么？ 为什么会发生？ 可能会发生什么？ 需要做什么？ 大数据分析其实就是对复杂问题进行分析与解决的过程。所以也是使用域这个解决过程的。在大数据分析中每一个步骤都有它自己独立的意义。可以帮助我们了解数据中到底包含了那些意义。每一个步骤都能让我们更深入的了解，深入的认识系统的情况，最终可以根据具体的数字化情况决定下一步的动作。
问题域：大数据分析只有需要解决这些问题时才有作用。如果业务需求不是在这个范围内的需求，则不适用与使用大数据分析方法进行问题的分析与解决。
解决域：针对不同的业务需求选择的不同的分析模型，也可以组合这些分析模型进行级联解决。在这些分析模型下定义了不同的分析算法，可以自顶向下的确定使用哪个分析模型，选用哪个分析算法，怎样进行组合。这样就形成了一套完整的大数据分析模型。
分析建模技术介绍 # 大数据分析为我们提供了什么样的方法，来解决问题。
大数据分析建模技术依赖的还是机器学习，人工智能提供算法。然后才可以对大量的数据进行聚类、分类、回归等等计算。在计算过程中需要对大量数据的访问，分布式计算等才是大数据技术。
要对数据中的特征进行量化或抽取特征需要进行机器学习。对数据进行分类也需要对其进行识别。针对下一阶段可能发生的情况还是需要量化。
数据挖掘建模过程 # 怎样建立数据挖掘模型。
目标定义需要定义清楚大数据需要解决的问题，并依据这些问题形成大数据分析时使用的指标体系。 抽取数据，使用能够反映整个情况的数据的选择方式是需要根据不同的方面进行选择的。 在大数据分析过程中数据质量是非常重要的。在数据分析、人工智能方面有一个重要的原则：Garbage In Garbage Out原则。就是说明数据质量的重要性。 建模：大数据分析与挖掘的基础。有了指标体系有了样本数据，需要通过模型算法得出业务所需要的结果。 模型评价：对建模结果的评价。评价也是有一套完整的系统的。 模型建立完成，并通过评价之后。就可以发布上线了。不过发不上线还是在线上持续反馈模型效果，并持续- 对建模结果进行优化。 - 目标定义 # 明确大数据分析目标，并之后针对目标进行分析与建设。 对大数据不了解导致看似明确的需求无法落地，所以需要进行引导性需求调研。
- 指标和维度 # 分析中关注的指标和维度，定义了之后能够分析哪些内容。 特征工程：数据和特征决定了机器学习的上限，而模型和算法只是逼近这个上限而已。 指标体系：指标可以分为绝对数指标和相对数指标，绝对数指标反映的是规模大小的指标 分析维度：维度是事物或现象的某种特征 分析模型介绍 # 分析模型的建立过程 在建模过程中需要不断的尝试不同的模型，不同的算法，不同的参数。所以，在建模过程中还是需要有不断的迭代的过程。</description></item><item><title>03 用Docker搭建Hive</title><link>https://guowei1651.github.io/architecture/16.practice/03-%E7%94%A8docker%E6%90%AD%E5%BB%BAhive/</link><pubDate>Sat, 22 Apr 2023 12:52:56 +0800</pubDate><guid>https://guowei1651.github.io/architecture/16.practice/03-%E7%94%A8docker%E6%90%AD%E5%BB%BAhive/</guid><description>背景 # 因为现在很多云都使用PAAS的方式提供大数据存储与计算的功能。作者就在思考他们是怎样实现的，并且提供出动态部署能力的大数据存储与计算过程的。所以，使用Docker进行Hadoop环境的搭建。并且为之后的K8s环境搭建提供一种思路。
在环境构建与使用的过程可以分为几个阶段：准备过程，搭建过程，配置过程，启动过程、测试过程。
准备过程 # 主要是准备软件包，并为Docker镜像与配置项分离做准备。
准备软件包 # 下载以下软件包：
hadoop-2.7.7 hive-2.3.6 mysql-connector-java-5.1.48 jdk-8u231-linux-x64.rpm 创建目录 # mkdir -p /home/docker/{centos_ssh,hadoop,hive,mysql} 上传文件 # cd /home/docker/hadoop rz 【hadoop-2.7.7.tar.gz，jdk-8u231-linux-x64.rpm】 cd /home/docker/hive rz 【apache-hive-2.3.6-bin.tar.gz，jdk-8u231-linux-x64.rpm，mysql-connector-java-5.1.48.tar.gz】 解压并Copy配置 # cd /home/docker/hadoop tar -xzvf hadoop-2.7.7.tar.gz cp -rf hadoop-2.7.7/etc/hadoop/* ./conf cd /home/docker/hive tar -xzvf apache-hive-2.3.6-bin.tar.gz tar -xzvf mysql-connector-java-5.1.48.tar.gz cp -rf apache-hive-2.3.6-bin/conf/ ./conf 创建my.cnf # 为Mysql配置my.cfg配置。这个配置是从CDH6.3的配置中拉过来的。
[mysqld] datadir=/var/lib/mysql socket=/var/lib/mysql/mysql.sock transaction-isolation = READ-COMMITTED # Disabling symbolic-links is recommended to prevent assorted security risks; # to do so, uncomment this line: symbolic-links = 0 key_buffer_size = 32M max_allowed_packet = 32M thread_stack = 256K thread_cache_size = 64 query_cache_limit = 8M query_cache_size = 64M query_cache_type = 1 max_connections = 550 #expire_logs_days = 10 #max_binlog_size = 100M #log_bin should be on a disk with enough free space.</description></item></channel></rss>